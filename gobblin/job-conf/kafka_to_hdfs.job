job.name=GobblinKafkaToHDFS
job.group=GobblinKafka
job.description=ingestion of kafka topic into hdfs
job.lock.enabled=false

kafka.brokers=kafka1:9092

source.class=gobblin.source.extractor.extract.kafka.KafkaSimpleSource
extract.namespace=gobblin.extract.kafka

writer.builder.class=gobblin.writer.SimpleDataWriterBuilder
writer.file.path.type=tablename
writer.destination.type=HDFS
writer.output.format=txt

data.publisher.type=gobblin.publisher.BaseDataPublisher

mr.job.max.mappers=1

metrics.reporting.file.enabled=true
metrics.log.dir=${env:GOBBLIN_WORK_DIR}/metrics
metrics.reporting.file.suffix=txt

bootstrap.with.offset=earliest

fs.uri=hdfs://namenode:9000
writer.fs.uri=hdfs://namenode:9000
state.store.fs.uri=hdfs://namenode:9000
